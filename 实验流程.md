> 进行中文文本摘要工作，需要完成以下工作内容：
> + 所做工作的目的：为了生成摘要从而减少索引证据的时间
> + 数据集中的事实部分的预处理
> + 证据和事实之间的信息关系，假设需要数据来证明
> + 证据全集作为事实去和事实进行比对


###实现baseline方法
 >各个方法中使用的公用接口，文书预处理以及内容编码
- 产生字典
字典的产生方式有多种思路：
> 直接对所有的数据集进行分词，对分词数据进行统计，然后去除频率低的词，作为词典数据
> 参考之前进行的最大匹配长度，得到的一些文书中的特有表达段，并将其作为分词的自定义词典
> 
> +  使用最大匹配的算法的目的是为了得到文书写作中特定的词级别的使用模式，
> +  比如，'经审理查明'这种短句子就是这种广义上的"词"，这种在文档中的固定搭配被当作一个特定的词来处理应但是比被额外分词处理来的好的
> +  但是使用最长匹配的方式还是会出现一些问题，这额问题主要是算法设计上的问题
> 在tf-idf值过高的一些词往往表示了每一个案件中的特有的信息，比如所人名或地名，使用这些信息
               
               
- 根据字典生成id序列向量
- 在字典中没有id的词分为两种情况，一种是诸如数字之类的停用词，一种是确实没有id，在处理某一个案件的时候，如果说出现了没有id的单词，那么这个单词是否就应该被抛弃呢，这个单词应但是在本文档中具有相当的特别性,所以应当给予一定的重视，**只是还没找到方法**
- 由于处理的是文本摘要的问题，会产生两段文本向量，分别是原文本以及长文本的代表向量

#### ABS(attention-based summarization)

 + 使用预处理的接口，生成文本向量
 + encoder将文本向量读入并训练，encoder所读入的数据要包括x和y，由于需要生成的字符编码作为y，这里就涉及到了y的一些问题
 > 
 >  在一开始进行encoder的时候，显然应但是没有y的值的，这个时候应当输入什么样的y值呢，
 >  输入的y值都是0，即作为unk输入
 >  输入y之后进行补0，即在embedding级上
 > 
 +   使用encoder的过程中已经使用了一次attention，这个attention是使用一个矩阵先后和文章内容以及yc相乘得到的
 +   yc的获取分为两种情况，
 >
 >   直接从正确的摘要当中提取
 >   从文本生成的摘要当中提取
 >   从当前的位置向前提取C个y作为上下文选择的内容
 >
 +   建立nnlm模型，将x和yc输入，得到每一个单词的概率分布
 +   从得到的概率分布中计算真实值的负对数似然值，并相加作为模型的损失函数
 +   使用mini-batch 随机梯度下降算法进行训练

####SESS(selection encoding sentence summarization)



####GEFG(gated evidence selection and fact generation model)

+  使用预处理的接口，生成文本向量
+  每一个文书作为一个单独训练的整体，这个整体中包含两个部分，分别是证据部分和事实部分，证据部分是多个证据文本段的集合，事实部分则是文书中的事实段落
   
   > 这么设计的原因在于：机器学习的训练中的batch的定义都是基于每一次梯度下降所使用的loss来源的向前传播的结果次数，在每一个文书的文本生成过程中都会进行几百次的生成，每一次的生成都代表着一个向前传播的结果，所以在每一个案件之中得到的loss的值都是多个结果的和，故可以看作是一个batch的loss值，同时考虑到使用了lstm等rnn需要对状态以及结果进行保存和进一步处理，所以将每一个案件作为一个单独的batch处理。

+  将证据文本输入到一个lstm中，每一个证据文本都输入到同一个lstm编码器中进行编码，得到每一步的输出，从而可以得到可以进行attention的向量序列。
+  使用当前生成文本的上下文向量与每一个步骤的输出进行attention，得到一个表示相关性的gate值，根据gate值的大小选择合适的文本进行摘要。
      > 
      > +  上下文的向量选择生成器lstm的当前状态，使用attention方式得到对应的向量当然也可以，但是这也是改进的方向
      > +  在得到gate value之后，可以选择gate值最高的证据作为当前生成选择的内容。
      > +  选择相关性最高的文本之后，使用该文本的最终状态作为其最终编码，当然还有更好的方式，值得改进。
      > 
+  利用选择的文本进行文本摘要操作，生成摘要中的下一个词
+  实验分析：
> 
> +  分析简单的ROUGE指标
> +  分析gate_value 在每一个案件上的分布
> +



