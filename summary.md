自动文本摘要总结
========

文本自动摘要任务的主要目的是从原始的文本描述中提取出一段摘要，可以一定程度上反映出原始文本的内容，或者`key point`。本工作主要目的是为了处理证据和事实之间的关系。通过阅读文书，可以发现文书中的事实段部分是对于文书中的证据描述的一定程度上的总结，所以尝试一下使用文本自动摘要的方式应用于证据到事实的转化。

### 背景介绍

文本自动摘要的问题由来已久，但是使用神经网路的方式进行摘要的过程还是从2015年兴起的。当时神经机器翻译的出现，使得借助神经网络进行文本生成有了一个非常合适的解决方案。
我所引用的参考文献如下

+ 最早的一篇是来自Facebook的Alexander M. Rush所发表的
《A Neural Attention Model for Abstractive Sentence Summarization》，在这篇文章中，使用attention网络从原始文本中抽取信息，encoder部分包含了上下文信息和原始数据的词袋模型向量。我一直认为这个部分有一点奇怪，因为词袋模型不能完整的表达原始文档的信息，而且在法律文书的应用层面上讲，法律文书中的词比较固定，会有更多细节的分析，所以这个设置方式我有一点存疑。在得到了encoder的向量之后，作者使用了一个神经语言模型对进行生成，神经语言模型的基本想法就是从把上下文和新的encoder作为输入，生成的目标是下一个单词，本质上是生成一个概率分布，从这个概率分布中找一个最大的候选词作为最终选定词。

+ 第二篇是《Selective Encoding for Abstractive Sentence Summarization》，作者是Qingyu Zhou，来自微软亚洲研究院，这篇文章的主要着眼点在于对原始文本信息的取舍，因为在文本摘要的问题中，原始数据肯定会包含很多冗余信息，这些信息将会对模型的摘要和判断产生不利影响，所以作者介绍了一个门控的机制，在每一个单词上提供一个gate权值，当gate值结果为1的时候，这个词的向量被当作信息输入模型，表示这个向量是有价值的，而gate值是0的时候，则表示这个词是没有意义的。通过这种方式，作者不仅得到了训练好的数据，还得到了一系列的gate值，这些gate值则可以反映出词的有意义程度。

### GEFG模型

#### 问题定义

法律文书中，证据文本和事实文本都是非常重要的组成部分，而且，这两个元素在内容上和含义上都具有较强的联系，从自然语言处理的角度，可以在一定的程度上认为事实是对证据的摘要性的总结。现如今，基于神经网络的文本摘要技术已经有很多了，综合证据与事实之间的关系特性，从已有的技术中选择适合的方式，并针对证据到事实转化这一应用情景进行相应的改进，便是本次工作的目标

+ 输入：包含多条独立文本的证据
+ 训练目标：可以生成对证据中的重要信息进行概括的事实文本
+ 具体约束：证据文本只选择描述类的证据，例如证人证词和被告人陈述等等；对数据进行的预处理包括去除停用词，在证据文本中不会包含具体的年月日以及地名人名。

所以我要做的问题着眼点在于在每一个生成的时间步中，从多个证据文本中选择一个最合适的参考文本，并用这个文本进行生成